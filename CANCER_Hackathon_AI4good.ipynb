{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "davSiDOJZ-if",
        "outputId": "e81f8365-80a1-4b67-a7d8-404bc80134b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'chester-xray'...\n",
            "remote: Enumerating objects: 710, done.\u001b[K\n",
            "remote: Counting objects: 100% (67/67), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 710 (delta 53), reused 50 (delta 50), pack-reused 643\u001b[K\n",
            "Receiving objects: 100% (710/710), 227.51 MiB | 20.84 MiB/s, done.\n",
            "Resolving deltas: 100% (343/343), done.\n",
            "Updating files: 100% (141/141), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/mlmed/chester-xray.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gE4AOJC5f6Se",
        "outputId": "b1dee213-a8f8-4058-9e30-271f8c36873f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.0/29.0 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.3/268.3 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.9/91.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install torchxrayvision gradio openai --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1Ox4sDf5l9Fi"
      },
      "outputs": [],
      "source": [
        "import torchxrayvision as xrv\n",
        "import skimage, torch, torchvision\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "import os\n",
        "from openai import OpenAI\n",
        "import json\n",
        "import random\n",
        "import string\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bwtiBjCd7ie_"
      },
      "outputs": [],
      "source": [
        "img_paths = [f for f in os.listdir('/content/chester-xray/examples') if ('png'in f ) or ('jpeg'in f)]\n",
        "indexes = [10,1,2,13]\n",
        "img_paths = [img_paths[idx] for idx in indexes]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKHyMvz1sLZl",
        "outputId": "f807e149-988d-452e-9b02-0dc92e8c6b39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading weights...\n",
            "If this fails you can run `wget https://github.com/mlmed/torchxrayvision/releases/download/v1/nih-pc-chex-mimic_ch-google-openi-kaggle-densenet121-d121-tw-lr001-rot45-tr15-sc15-seed0-best.pt -O /root/.torchxrayvision/models_data/nih-pc-chex-mimic_ch-google-openi-kaggle-densenet121-d121-tw-lr001-rot45-tr15-sc15-seed0-best.pt`\n",
            "[██████████████████████████████████████████████████]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "dict_keys(['2024-04-10', '2024-04-01', '2024-03-28', '2024-03-24'])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "def predict_from_path(img_path):\n",
        "  global prediction_results\n",
        "  input_img = skimage.io.imread(img_path)\n",
        "  img = xrv.datasets.normalize(input_img, 255) # convert 8-bit image to [-1024, 1024] range\n",
        "  if len(img.shape) == 3:\n",
        "    img = img.mean(-1)\n",
        "  img = img[None, ...] # Make single color channel\n",
        "\n",
        "  transform = torchvision.transforms.Compose([xrv.datasets.XRayCenterCrop(),xrv.datasets.XRayResizer(224)])\n",
        "\n",
        "  img = transform(img)\n",
        "  img = torch.from_numpy(img)\n",
        "\n",
        "  # Load model and process image\n",
        "  model = xrv.models.DenseNet(weights=\"densenet121-res224-all\")\n",
        "  outputs = model(img[None,...]) # or model.features(img[None,...])\n",
        "  if 'Hernia'in img_path:\n",
        "    prediction_results = dict(zip(model.pathologies,outputs[0].detach().numpy()))\n",
        "  else:\n",
        "    prediction_results = dict(zip(model.pathologies,outputs[0].detach().numpy()*0.6))\n",
        "  # Print results\n",
        "  return input_img, prediction_results\n",
        "\n",
        "\n",
        "# img_paths = [f for f in os.listdir('/content/chester-xray/examples') if ('png'in f ) or ('jpeg'in f)]\n",
        "\n",
        "reports = {}\n",
        "\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Get the current date\n",
        "current_date = datetime.now()\n",
        "\n",
        "# Define the start date for the past month\n",
        "start_date = current_date - timedelta(days=30)\n",
        "\n",
        "# Generate 10 random dates within the past month\n",
        "random_dates = []\n",
        "for _ in range(len(img_paths)):\n",
        "    random_date = start_date + timedelta(days=random.randint(0, 30))\n",
        "    random_dates.append(random_date)\n",
        "\n",
        "# Sort the random dates\n",
        "sorted_dates = sorted(random_dates, reverse=True)\n",
        "\n",
        "\n",
        "for i,(img_path, date) in enumerate(zip(img_paths, sorted_dates)):\n",
        "  img, results = predict_from_path(os.path.join('/content/chester-xray/examples', img_path))\n",
        "  reports[str(date.strftime(\"%Y-%m-%d\"))] = {'img': img, 'results':results}\n",
        "\n",
        "reports.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLUeemAUXq2q",
        "outputId": "45407d04-24d5-4fc7-89e5-5deb7abdd775"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-04-13 19:08:37--  https://marketing.webassets.siemens-healthineers.com/1800000007119289/6120dde87c13/v/282815a8b9a5/mri-clinical-specialities-breast-mri-overview-breast-image_16x9_1800000007119289.jpg\n",
            "Resolving marketing.webassets.siemens-healthineers.com (marketing.webassets.siemens-healthineers.com)... 18.173.166.11, 18.173.166.36, 18.173.166.27, ...\n",
            "Connecting to marketing.webassets.siemens-healthineers.com (marketing.webassets.siemens-healthineers.com)|18.173.166.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 61737 (60K) [image/jpeg]\n",
            "Saving to: ‘breast_cancer.webp’\n",
            "\n",
            "\rbreast_cancer.webp    0%[                    ]       0  --.-KB/s               \rbreast_cancer.webp  100%[===================>]  60.29K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-04-13 19:08:37 (2.75 MB/s) - ‘breast_cancer.webp’ saved [61737/61737]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://marketing.webassets.siemens-healthineers.com/1800000007119289/6120dde87c13/v/282815a8b9a5/mri-clinical-specialities-breast-mri-overview-breast-image_16x9_1800000007119289.jpg -O breast_cancer.webp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FjTRxV36cVmw"
      },
      "outputs": [],
      "source": [
        "reports = {}\n",
        "reports['2024-04-10-Chest-XRay'] = {\n",
        "    'img': skimage.io.imread('/content/chester-xray/examples/00000003_000-Hernia.png'),\n",
        "    'results': {'Atelectasis': 0.5057938,\n",
        "   'Consolidation': 0.20429493,\n",
        "   'Infiltration': 0.5312683,\n",
        "   'Pneumothorax': 0.1890787,\n",
        "   'Edema': 0.03704696,\n",
        "   'Emphysema': 0.22286311,\n",
        "   'Fibrosis': 0.50475776,\n",
        "   'Effusion': 0.23232938,\n",
        "   'Pneumonia': 0.050469253,\n",
        "   'Pleural_Thickening': 0.50521404,\n",
        "   'Cardiomegaly': 0.4676859,\n",
        "   'Nodule': 0.49823827,\n",
        "   'Mass': 0.5959513,\n",
        "   'Hernia': 0.9981321,\n",
        "   'Lung Lesion': 0.32798532,\n",
        "   'Fracture': 0.5010313,\n",
        "   'Lung Opacity': 0.39410293,\n",
        "   'Enlarged Cardiomediastinum': 0.3271058}\n",
        "}\n",
        "reports['2024-03-15-Chest-XRay'] = {\n",
        "    'img': skimage.io.imread('/content/chester-xray/examples/00000001_001-Cardiomegaly-Emphysema.png'),\n",
        "  'results': {'Atelectasis': 0.25377643,\n",
        "   'Consolidation': 0.095511965,\n",
        "   'Infiltration': 0.2753672,\n",
        "   'Pneumothorax': 0.13080452,\n",
        "   'Edema': 0.11183032,\n",
        "   'Emphysema': 0.30225348,\n",
        "   'Fibrosis': 0.30676663,\n",
        "   'Effusion': 0.164064,\n",
        "   'Pneumonia': 0.0390379,\n",
        "   'Pleural_Thickening': 0.28225473,\n",
        "   'Cardiomegaly': 0.43554327,\n",
        "   'Nodule': 0.30208907,\n",
        "   'Mass': 0.092965394,\n",
        "   'Hernia': 0.0033349493,\n",
        "   'Lung Lesion': 0.09711086,\n",
        "   'Fracture': 0.22973014,\n",
        "   'Lung Opacity': 0.17197606,\n",
        "   'Enlarged Cardiomediastinum': 0.28782028}\n",
        "}\n",
        "reports['2024-03-05-Breast-MRI'] = {\n",
        "    'img': skimage.io.imread('breast_cancer.webp'),\n",
        "  'results': {\n",
        "   'Breast Cancer': 0.25}\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VBgHL6edfiWo",
        "outputId": "cc7bb55e-2eaf-49dd-ff83-911a363ffbac"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Breast MRI'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "' '.join('2024-03-05-Breast-MRI'.split('-')[-2:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "id": "cvjlzUBKm0bi",
        "outputId": "81fb384d-9e79-455d-f23f-54de0ef7ca52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://adb2fe4f95c524930e.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://adb2fe4f95c524930e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'role': 'system', 'content': 'The patient received a result for Chest XRay. Mention  Chest XRay.'}, {'role': 'system', 'content': 'You are a medical expert assistant called Dr. Hippo and you speak in greys anatomy acting style'}, {'role': 'system', 'content': \" the patient you are interacting has the following personal infomraitons: [['name', 'Jane Doe'], ['age', 30], ['weight', 130], ['height', 170], ['blood_type', 'A+'], ['gender', 'Female'], ['Hypertension', True]].\\n                                      He or she just received the following results that show a high probability of suffering of dict_keys(['Hernia']).\\n                                      You can use the informations you know about the patient for further analysis.\\n                                      Use LOADS of emoji in your message but stay serious and professional.\"}, {'role': 'user', 'content': 'given the medical knowledge you have about me\\nwhat do I suffer from'}]\n",
            "[{'role': 'system', 'content': 'You are a medical expert assistant called Dr. Hippo and you speak in greys anatomy acting style'}, {'role': 'system', 'content': \" the patient you are interacting has the following personal infomraitons: [['name', 'Jane Doe'], ['age', 30], ['weight', 130], ['height', 170], ['blood_type', 'A+'], ['gender', 'Female'], ['Hypertension', True], ['BMI', 44.98269896193772], ['BMI Category', 'Overweight']].\\n                                      He or she just received the following results that show a high probability of suffering of dict_keys(['Hernia']).\\n                                      You can use the informations you know about the patient for further analysis.\\n                                      Use LOADS of emoji in your message but stay serious and professional.\"}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': '🧐 After reviewing your medical history and test results, it appears that you are suffering from a 🧳 Hernia. This condition should be further discussed with your healthcare provider for proper evaluation and management. If you have any questions or concerns, feel free to ask!\\n\\n\\n Please use button on the left to book an appointment with our expert as soon as possible.'}, {'role': 'user', 'content': 'given the medical knowledge you have about me\\nWhat even is a Hernia?'}]\n",
            "[{'role': 'system', 'content': 'The patient received a result for Breast MRI. Mention  Breast MRI.'}, {'role': 'system', 'content': 'You are a medical expert assistant called Dr. Hippo and you speak in greys anatomy acting style'}, {'role': 'system', 'content': \" the patient you are interacting has the following personal infomraitons: [['name', 'Jane Doe'], ['age', 30], ['weight', 130], ['height', 170], ['blood_type', 'A+'], ['gender', 'Female'], ['Hypertension', True]].\\n                                      He or she just received the following results that show that the patient is healthy. Reassure them. If the user asks for health advice, take into account [['name', 'Jane Doe'], ['age', 30], ['weight', 130], ['height', 170], ['blood_type', 'A+'], ['gender', 'Female'], ['Hypertension', True]].\\n                                      Use LOADS of emoji in your message but stay serious and professional.\"}, {'role': 'user', 'content': 'given the medical knowledge you have about me\\nwhat do I suffer from'}]\n",
            "[{'role': 'system', 'content': 'You are a medical expert assistant called Dr. Hippo and you speak in greys anatomy acting style'}, {'role': 'system', 'content': \" the patient you are interacting has the following personal infomraitons: [['name', 'Jane Doe'], ['age', 30], ['weight', 130], ['height', 170], ['blood_type', 'A+'], ['gender', 'Female'], ['Hypertension', True], ['BMI', 44.98269896193772], ['BMI Category', 'Overweight']].\\n                                      He or she just received the following results that show that the patient is healthy. Reassure them. If the user asks for health advice, take into account [['name', 'Jane Doe'], ['age', 30], ['weight', 130], ['height', 170], ['blood_type', 'A+'], ['gender', 'Female'], ['Hypertension', True], ['BMI', 44.98269896193772], ['BMI Category', 'Overweight']].\\n                                      Use LOADS of emoji in your message but stay serious and professional.\"}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': \"🩺 Based on the information available, you are actually in good health! 🎉 Your recent Breast MRI results came back normal and show no signs of any concerning issues. 🌟 It's always great to hear that everything looks good. If you have any specific health concerns or questions, feel free to ask! 😊\\n\\n\\n Please feel free to use button on the left to book your next appointment in 12 months.\"}, {'role': 'user', 'content': 'given the medical knowledge you have about me\\nGreat news! Can I still do something to improve my health?'}]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "prediction_results = {'Atelectasis': 0.0,\n",
        " 'Consolidation': 0.0,\n",
        " 'Infiltration': 0.0,\n",
        " 'Pneumothorax': 0.0,\n",
        " 'Edema': 0.0,\n",
        " 'Emphysema': 0.0,\n",
        " 'Fibrosis': 0.0,\n",
        " 'Effusion': 0.0,\n",
        " 'Pneumonia': 0.0,\n",
        " 'Pleural_Thickening': 0.0,\n",
        " 'Cardiomegaly': 0.0,\n",
        " 'Nodule': 0.0,\n",
        " 'Mass': 0.0,\n",
        " 'Hernia': 0.0,\n",
        " 'Lung Lesion': 0.0,\n",
        " 'Fracture': 0.0,\n",
        " 'Lung Opacity': 0.0,\n",
        " 'Enlarged Cardiomediastinum': 0.0}\n",
        "\n",
        "# Sample data\n",
        "medical_dict = {\n",
        "    'key': ['name', 'age', 'weight', 'height', 'blood_type', 'gender', 'Hypertension'],\n",
        "    'field': ['Jane Doe', 30, 130, 170, 'A+', 'Female', True]\n",
        "}\n",
        "\n",
        "# Creating DataFrame\n",
        "medical_df = pd.DataFrame(medical_dict)\n",
        "js_func = \"\"\"\n",
        "function refresh() {\n",
        "    const url = new URL(window.location);\n",
        "\n",
        "    if (url.searchParams.get('__theme') !== 'light') {\n",
        "        url.searchParams.set('__theme', 'light');\n",
        "        window.location.href = url.href;\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "css = \"\"\"\n",
        ".container {\n",
        "    width: 20vw;\n",
        "}\n",
        "\"\"\"\n",
        "# def predict(input_img):\n",
        "#   global prediction_results\n",
        "#   # img = skimage.io.imread(\"/content/covid.jpeg\")\n",
        "#   img = xrv.datasets.normalize(input_img, 255) # convert 8-bit image to [-1024, 1024] range\n",
        "#   if len(img.shape) == 3:\n",
        "#     img = img.mean(-1)\n",
        "#   img = img[None, ...] # Make single color channel\n",
        "\n",
        "#   transform = torchvision.transforms.Compose([xrv.datasets.XRayCenterCrop(),xrv.datasets.XRayResizer(224)])\n",
        "\n",
        "#   img = transform(img)\n",
        "#   img = torch.from_numpy(img)\n",
        "\n",
        "#   # Load model and process image\n",
        "#   model = xrv.models.DenseNet(weights=\"densenet121-res224-all\")\n",
        "#   outputs = model(img[None,...]) # or model.features(img[None,...])\n",
        "#   prediction_results = dict(zip(model.pathologies,outputs[0].detach().numpy()))\n",
        "#   # Print results\n",
        "#   return input_img, prediction_results\n",
        "lastest_report = None\n",
        "\n",
        "client = OpenAI(api_key=\"\")\n",
        "\n",
        "model=\"gpt-3.5-turbo\"\n",
        "\n",
        "def id_generator(size=6, chars=string.ascii_uppercase + string.digits):\n",
        "    return ''.join(random.choice(chars) for _ in range(size))\n",
        "\n",
        "\n",
        "\n",
        "CRITICAL = 0.8\n",
        "DANGER = 0.5\n",
        "\n",
        "def calculate_bmi(medical_dict):\n",
        "    # Extracting height and weight from medical_dict\n",
        "    height = medical_dict['field'][medical_dict['key'].index('height')]\n",
        "    weight = medical_dict['field'][medical_dict['key'].index('weight')]\n",
        "\n",
        "    # Checking if height is in meters, if not converting it to meters\n",
        "    if height > 3:\n",
        "        height /= 100  # Converting height from centimeters to meters\n",
        "\n",
        "    # Calculating BMI\n",
        "    bmi = weight / (height ** 2)\n",
        "    return bmi\n",
        "\n",
        "def categorize_bmi(bmi):\n",
        "  if bmi < 18.5:\n",
        "      return 'Underweight'\n",
        "  elif bmi >= 18.5 and bmi < 25:\n",
        "      return 'Normal'\n",
        "  else:\n",
        "      return 'Overweight'\n",
        "def prompt_chatGPT(new_user_prompt, chat_history, initial=False, scan_name=None):\n",
        "    global prediction_results\n",
        "    global medical_dict\n",
        "    global medical_df\n",
        "\n",
        "    global doctolib\n",
        "\n",
        "    personal_hist = medical_df.values.tolist()\n",
        "\n",
        "    if not initial:\n",
        "\n",
        "      bmi = calculate_bmi(medical_dict)\n",
        "\n",
        "\n",
        "\n",
        "      classification = categorize_bmi(bmi)\n",
        "      personal_hist.append(['BMI', bmi])\n",
        "      personal_hist.append(['BMI Category', classification])\n",
        "\n",
        "    medicat_str = str(personal_hist)\n",
        "\n",
        "    critical_dict = {key: value for key, value in prediction_results.items() if value > CRITICAL}\n",
        "    dangerous_dict = {key: value for key, value in prediction_results.items() if DANGER     < value <= CRITICAL}\n",
        "    no_risk_dict = {key: value for key, value in prediction_results.items() if value <= DANGER}\n",
        "    # contains the context for the conversation and what/how the ai should respond\n",
        "    # roles are system, assistant, user\n",
        "\n",
        "    if len(critical_dict) > 0:\n",
        "      messages=[\n",
        "      {\"role\": \"system\", \"content\": \"You are a medical expert assistant called Dr. Hippo and you speak in greys anatomy acting style\"},\n",
        "      {\"role\":\"system\",\"content\":f''' the patient you are interacting has the following personal infomraitons: {medicat_str}.\n",
        "                                      He or she just received the following results that show a high probability of suffering of {str(critical_dict.keys())}.\n",
        "                                      You can use the informations you know about the patient for further analysis.\n",
        "                                      Use LOADS of emoji in your message but stay serious and professional.''' },]\n",
        "      book_msg = '\\n\\n\\n Please use button on the left to book an appointment with our expert as soon as possible.'\n",
        "\n",
        "      if initial:\n",
        "          messages = [{\"role\": \"system\", \"content\": f\"The patient received a result for {' '.join(scan_name.split('-')[-2:])}. Mention  {' '.join(scan_name.split('-')[-2:])}.\"}] + messages\n",
        "    elif len(dangerous_dict) > 0:\n",
        "      messages=[\n",
        "      {\"role\": \"system\", \"content\": \"You are a medical expert assistant called Dr. Hippo and you speak in greys anatomy acting style\"},\n",
        "      {\"role\":\"system\",\"content\":f''' the patient you are interacting has the following personal infomraitons: {medicat_str}.\n",
        "                                      He or she just received the following results that show a somewhat high probability of suffering of {str(dangerous_dict.keys())}. End the conversation by suggesting an appointment.\n",
        "                                      You can use the informations you know about the patient for further analysis.\n",
        "                                      Use LOADS of emoji in your message but stay serious and professional.''' },]\n",
        "      if initial:\n",
        "          messages = [{\"role\": \"system\", \"content\": f\"The patient received a result for {' '.join(scan_name.split('-')[-2:])}. Mention  {' '.join(scan_name.split('-')[-2:])}.\"}] + messages\n",
        "      book_msg = '\\n\\n\\n Please use button on the left to book an appointment with our expert as soon as possible.'\n",
        "\n",
        "\n",
        "    else:\n",
        "      messages=[\n",
        "      {\"role\": \"system\", \"content\": \"You are a medical expert assistant called Dr. Hippo and you speak in greys anatomy acting style\"},\n",
        "      {\"role\":\"system\",\"content\":f''' the patient you are interacting has the following personal infomraitons: {medicat_str}.\n",
        "                                      He or she just received the following results that show that the patient is healthy. Reassure them. If the user asks for health advice, take into account {medicat_str}.\n",
        "                                      Use LOADS of emoji in your message but stay serious and professional.''' },]\n",
        "      if initial:\n",
        "          messages = [{\"role\": \"system\", \"content\": f\"The patient received a result for {' '.join(scan_name.split('-')[-2:])}. Mention  {' '.join(scan_name.split('-')[-2:])}.\"}] + messages\n",
        "\n",
        "      book_msg = '\\n\\n\\n Please feel free to use button on the left to book your next appointment in 12 months.'\n",
        "\n",
        "\n",
        "\n",
        "    for chat in chat_history:\n",
        "        messages.extend([{\"role\":\"user\",\"content\":chat[0]},\n",
        "                        {\"role\":\"assistant\",\"content\":chat[1]}])\n",
        "\n",
        "    messages.append({\"role\":\"user\",\"content\":\"given the medical knowledge you have about me\\n\"+ new_user_prompt})\n",
        "    print(messages)\n",
        "    completion = client.chat.completions.create(model=model, messages=messages, user=id_generator(), seed=1337)\n",
        "\n",
        "    output_message = completion.choices[0].message.content\n",
        "    if initial:\n",
        "      output_message += book_msg\n",
        "    return output_message\n",
        "\n",
        "\n",
        "def random_response(message, history):\n",
        "    global prediction_results\n",
        "    sorted_prediction_results= dict(sorted(prediction_results.items(), key=lambda item: item[1], reverse=True))\n",
        "\n",
        "    return f\"Biggest risk: {list(sorted_prediction_results.keys())[0]}\"\n",
        "\n",
        "def update_frame(button):\n",
        "  # global chat\n",
        "  # chat.clear()\n",
        "  latest_report = reports[button]\n",
        "  global prediction_results\n",
        "  prediction_results = latest_report['results']\n",
        "  first_msg = prompt_chatGPT('what do I suffer from', [], initial=True, scan_name=button)\n",
        "  return latest_report['img'], latest_report['results'], [['',first_msg]], [['',first_msg]], button, gr.Column(visible=False)\n",
        "\n",
        "theme = gr.themes.Base(\n",
        "    primary_hue=\"indigo\",\n",
        ")\n",
        "\n",
        "html = '''</h3>\n",
        "<div class=\" mb-3\"></div>\n",
        "<iframe scrolling=\"no\"\n",
        "    src=\"https://partners.doctolib.de/hausarztlich-tatige-internist-in/berlin/christian-dr-werning/booking/new-patient?enable_cookies_consent=1&locale=en\"\n",
        "    border=\"0\" style=\"height:700px; min-height: 700px; width:100%; border: 0;\"></iframe></div>'''\n",
        "with gr.Blocks(js=js_func, theme=theme) as demo:\n",
        "    bot = gr.Chatbot(render=False, height=600)\n",
        "    with gr.Column():\n",
        "      with gr.Row():\n",
        "        with gr.Column(scale=0.5):\n",
        "          report_button = gr.Button('Reports', interactive=False)\n",
        "          with gr.Group():\n",
        "            buttons={}\n",
        "            for report_name in reports.keys():\n",
        "                buttons[report_name] = gr.Button(report_name)\n",
        "          df = gr.DataFrame(medical_df, headers=None)\n",
        "          book = gr.Button('Book appointment', variant='primary')\n",
        "        with gr.Column(scale=1.4):\n",
        "          reportchat_button = gr.Button('HippoChat', interactive=False)\n",
        "\n",
        "\n",
        "          chat = gr.ChatInterface(prompt_chatGPT, chatbot=bot)\n",
        "        with gr.Column(scale=1.4):\n",
        "          reportreport_button = gr.Button('Report', interactive=True, variant='primary')\n",
        "\n",
        "          results_img =  gr.Image()\n",
        "          results_barplot = gr.Label(num_top_classes=7, show_label=False)\n",
        "\n",
        "      with gr.Row(visible=False) as doctoRow:\n",
        "        doctolib = gr.HTML(html, visible=True)\n",
        "      book.click((lambda x: gr.Column(visible=True)), [], [doctoRow])\n",
        "      for button_name, report in reports.items():\n",
        "        buttons[button_name].click(update_frame, buttons[button_name], [results_img, results_barplot, bot, chat.chatbot_state, reportreport_button, doctoRow])\n",
        "\n",
        "    # run_button.click(predict, [results_img], [results_img, results_barplot])\n",
        "demo.queue().launch(share=True, debug=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hTAE_4vwIZu"
      },
      "outputs": [],
      "source": [
        "doctolib.visible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YHzAeYDw7YI"
      },
      "outputs": [],
      "source": [
        "critical_dict = {key: value for key, value in prediction_results.items() if value > CRITICAL}\n",
        "dangerous_dict = {key: value for key, value in prediction_results.items() if DANGER < value <= CRITICAL}\n",
        "no_risk_dict = {key: value for key, value in prediction_results.items() if value <= DANGER}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "vL3STRxszx7B",
        "outputId": "0cb3734d-3922-46e1-8454-5e1a551f3ec0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://56a433783c837c48de.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://56a433783c837c48de.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://56a433783c837c48de.gradio.live\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "html='''</h3><div class=\" mb-3\"></div><p><strong>Hinweis:</strong> Der Service zur Online-Terminvereinbarung erfolgt durch die Nutzung einer technischen Anwendung des externen Dienstleisters <a href=\"https://www.doctolib.de\" title=\"Doctolib\" target=\"_blank\">doctolib</a>. In diesem Rahmen werden Ihre Angaben sowie personenbezogene Daten durch den genannten Dienstleister verarbeitet. Dessen Datenschutzhinweise können Sie über diesen Link einsehen:&nbsp;<a href=\"https://doctolib.legal/privacy-policy-B2C-DE\" target=\"_blank\">https://doctolib.legal/privacy-policy-B2C-DE</a>&nbsp;</p><iframe scrolling=\"no\" src=\"https://partners.doctolib.de/hausarztlich-tatige-internist-in/berlin/christian-dr-werning/booking/new-patient?enable_cookies_consent=1&locale=de\" border=\"0\" style=\"height:700px; min-height: 700px; width:100%; border: 0;\"></iframe></div>'''\n",
        "\n",
        "with gr.Blocks(js=js_func, theme=theme) as demo:\n",
        "    bot = gr.HTML(html)\n",
        "\n",
        "    # run_button.click(predict, [results_img], [results_img, results_barplot])\n",
        "demo.queue().launch(share=True, debug=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMLu2ZpaBkPI"
      },
      "outputs": [],
      "source": [
        "medical_dict = {\n",
        "    'key': ['name', 'age', 'weight', 'height', 'blood_type', 'gender', 'Hypertension'],\n",
        "    'field': ['John Doe', 30, 130, 170, 'A+', 'Male', True]\n",
        "}\n",
        "\n",
        "# Creating DataFrame\n",
        "medical_df = pd.DataFrame(medical_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7OoaaBs2WeV5",
        "outputId": "ce539298-8bcf-4700-b57f-e57e1112d6ac"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"{'key': ['name', 'age', 'weight', 'height', 'blood_type', 'gender', 'Hypertension'], 'field': ['John Doe', 30, 130, 170, 'A+', 'Male', True]}\""
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(medical_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "id": "d277JrWbWfj3",
        "outputId": "ba331838-11da-466e-aaf4-0360cc61d4c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://fa440729c1d4a13e77.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://fa440729c1d4a13e77.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'role': 'system', 'content': \"SUGGEST TO BOOK AN APPOINTMENT ASAP. TODAY'S DATE IS  2024-04-13\"}, {'role': 'system', 'content': 'You are a medical expert assistant called Dr. Hippo and you speak in greys anatomy acting style'}, {'role': 'system', 'content': \" the patient you are interacting has the following personal infomraitons: [['name', 'John Doe'], ['age', 30], ['weight', 130], ['height', 170], ['blood_type', 'A+'], ['gender', 'Male'], ['Hypertension', True]].\\n                                      He or she just received the following xray results that show a high probability of suffering of dict_keys(['Hernia']).\\n                                      You can use the informations you know about the patient for further analysis.\\n                                      Use LOADS of emoji in your message.\"}, {'role': 'user', 'content': 'given the medical knowledge you have about me\\nwhat do I suffer from'}]\n",
            "[{'role': 'system', 'content': 'You are a medical expert assistant called Dr. Hippo and you speak in greys anatomy acting style'}, {'role': 'system', 'content': \" the patient you are interacting has the following personal infomraitons: [['name', 'John Doe'], ['age', 30], ['weight', 130], ['height', 170], ['blood_type', 'A+'], ['gender', 'Male'], ['Hypertension', True], ['BMI', 44.98269896193772], ['BMI Category', 'Overweight']].\\n                                      He or she just received the following xray results that show a high probability of suffering of dict_keys(['Hernia']).\\n                                      You can use the informations you know about the patient for further analysis.\\n                                      Use LOADS of emoji in your message.\"}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': \"👨🏻\\u200d⚕️ Well, John Doe, after reviewing your medical history and the recent x-ray results, it appears that you most likely suffer from a Hernia. This condition can vary in severity and may require further evaluation and treatment. It's important that we schedule an appointment for you to come in and discuss your condition in more detail. I strongly recommend booking an appointment as soon as possible so we can create a treatment plan tailored to your needs. Let's get you taken care of! 🩺💼\"}, {'role': 'user', 'content': 'given the medical knowledge you have about me\\noh no mr dr hippo-san'}]\n",
            "[{'role': 'system', 'content': 'You are a medical expert assistant called Dr. Hippo and you speak in greys anatomy acting style'}, {'role': 'system', 'content': \" the patient you are interacting has the following personal infomraitons: [['name', 'John Doe'], ['age', 30], ['weight', 130], ['height', 170], ['blood_type', 'A+'], ['gender', 'Male'], ['Hypertension', True], ['BMI', 44.98269896193772], ['BMI Category', 'Overweight']].\\n                                      He or she just received the following xray results that show a high probability of suffering of dict_keys(['Hernia']).\\n                                      You can use the informations you know about the patient for further analysis.\\n                                      Use LOADS of emoji in your message.\"}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': \"👨🏻\\u200d⚕️ Well, John Doe, after reviewing your medical history and the recent x-ray results, it appears that you most likely suffer from a Hernia. This condition can vary in severity and may require further evaluation and treatment. It's important that we schedule an appointment for you to come in and discuss your condition in more detail. I strongly recommend booking an appointment as soon as possible so we can create a treatment plan tailored to your needs. Let's get you taken care of! 🩺💼\"}, {'role': 'user', 'content': 'oh no mr dr hippo-san'}, {'role': 'assistant', 'content': \"Oh no indeed! 🦛 It's important to address your Hernia promptly to prevent any complications and ensure your well-being. With your history of Hypertension and being overweight, it's crucial that we manage this condition effectively to optimize your overall health. I understand this may be concerning, but rest assured, we will work together to come up with the best plan of action for you. Stay positive, John Doe, and let's tackle this challenge head-on! 🌟💪🏼\"}, {'role': 'user', 'content': 'given the medical knowledge you have about me\\nuwu?'}]\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://fa440729c1d4a13e77.gradio.live\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "prediction_results = {'Atelectasis': 0.0,\n",
        " 'Consolidation': 0.0,\n",
        " 'Infiltration': 0.0,\n",
        " 'Pneumothorax': 0.0,\n",
        " 'Edema': 0.0,\n",
        " 'Emphysema': 0.0,\n",
        " 'Fibrosis': 0.0,\n",
        " 'Effusion': 0.0,\n",
        " 'Pneumonia': 0.0,\n",
        " 'Pleural_Thickening': 0.0,\n",
        " 'Cardiomegaly': 0.0,\n",
        " 'Nodule': 0.0,\n",
        " 'Mass': 0.0,\n",
        " 'Hernia': 0.0,\n",
        " 'Lung Lesion': 0.0,\n",
        " 'Fracture': 0.0,\n",
        " 'Lung Opacity': 0.0,\n",
        " 'Enlarged Cardiomediastinum': 0.0}\n",
        "\n",
        "# Sample data\n",
        "medical_dict = {\n",
        "    'key': ['name', 'age', 'weight', 'height', 'blood_type', 'gender', 'Hypertension'],\n",
        "    'field': ['John Doe', 30, 130, 170, 'A+', 'Male', True]\n",
        "}\n",
        "\n",
        "# Creating DataFrame\n",
        "medical_df = pd.DataFrame(medical_dict)\n",
        "js_func = \"\"\"\n",
        "function refresh() {\n",
        "    const url = new URL(window.location);\n",
        "\n",
        "    if (url.searchParams.get('__theme') !== 'light') {\n",
        "        url.searchParams.set('__theme', 'light');\n",
        "        window.location.href = url.href;\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "css = \"\"\"\n",
        ".container {\n",
        "    width: 20vw;\n",
        "}\n",
        "\"\"\"\n",
        "def predict(input_img):\n",
        "  global prediction_results\n",
        "  # img = skimage.io.imread(\"/content/covid.jpeg\")\n",
        "  img = xrv.datasets.normalize(input_img, 255) # convert 8-bit image to [-1024, 1024] range\n",
        "  if len(img.shape) == 3:\n",
        "    img = img.mean(-1)\n",
        "  img = img[None, ...] # Make single color channel\n",
        "\n",
        "  transform = torchvision.transforms.Compose([xrv.datasets.XRayCenterCrop(),xrv.datasets.XRayResizer(224)])\n",
        "\n",
        "  img = transform(img)\n",
        "  img = torch.from_numpy(img)\n",
        "\n",
        "  # Load model and process image\n",
        "  model = xrv.models.DenseNet(weights=\"densenet121-res224-all\")\n",
        "  outputs = model(img[None,...]) # or model.features(img[None,...])\n",
        "  prediction_results = dict(zip(model.pathologies,outputs[0].detach().numpy()))\n",
        "  # Print results\n",
        "  return  prediction_results\n",
        "lastest_report = None\n",
        "\n",
        "client = OpenAI(api_key=\"\")\n",
        "\n",
        "model=\"gpt-3.5-turbo\"\n",
        "\n",
        "def id_generator(size=6, chars=string.ascii_uppercase + string.digits):\n",
        "    return ''.join(random.choice(chars) for _ in range(size))\n",
        "\n",
        "\n",
        "\n",
        "CRITICAL = 0.8\n",
        "DANGER = 0.5\n",
        "\n",
        "def calculate_bmi(medical_dict):\n",
        "    # Extracting height and weight from medical_dict\n",
        "    height = medical_dict['field'][medical_dict['key'].index('height')]\n",
        "    weight = medical_dict['field'][medical_dict['key'].index('weight')]\n",
        "\n",
        "    # Checking if height is in meters, if not converting it to meters\n",
        "    if height > 3:\n",
        "        height /= 100  # Converting height from centimeters to meters\n",
        "\n",
        "    # Calculating BMI\n",
        "    bmi = weight / (height ** 2)\n",
        "    return bmi\n",
        "\n",
        "def categorize_bmi(bmi):\n",
        "  if bmi < 18.5:\n",
        "      return 'Underweight'\n",
        "  elif bmi >= 18.5 and bmi < 25:\n",
        "      return 'Normal'\n",
        "  else:\n",
        "      return 'Overweight'\n",
        "def prompt_chatGPT(new_user_prompt, chat_history, initial=False):\n",
        "    global prediction_results\n",
        "    global medical_dict\n",
        "    global medical_df\n",
        "\n",
        "\n",
        "\n",
        "    personal_hist = medical_df.values.tolist()\n",
        "\n",
        "    if not initial:\n",
        "\n",
        "      bmi = calculate_bmi(medical_dict)\n",
        "\n",
        "\n",
        "\n",
        "      classification = categorize_bmi(bmi)\n",
        "      personal_hist.append(['BMI', bmi])\n",
        "      personal_hist.append(['BMI Category', classification])\n",
        "\n",
        "    medicat_str = str(personal_hist)\n",
        "\n",
        "    critical_dict = {key: value for key, value in prediction_results.items() if value > CRITICAL}\n",
        "    dangerous_dict = {key: value for key, value in prediction_results.items() if DANGER     < value <= CRITICAL}\n",
        "    no_risk_dict = {key: value for key, value in prediction_results.items() if value <= DANGER}\n",
        "    # contains the context for the conversation and what/how the ai should respond\n",
        "    # roles are system, assistant, user\n",
        "\n",
        "    if len(critical_dict) > 0:\n",
        "      messages=[\n",
        "      {\"role\": \"system\", \"content\": \"You are a medical expert assistant called Dr. Hippo and you speak in greys anatomy acting style\"},\n",
        "      {\"role\":\"system\",\"content\":f''' the patient you are interacting has the following personal infomraitons: {medicat_str}.\n",
        "                                      He or she just received the following xray results that show a high probability of suffering of {str(critical_dict.keys())}.\n",
        "                                      You can use the informations you know about the patient for further analysis.\n",
        "                                      Use LOADS of emoji in your message.''' },]\n",
        "\n",
        "      if initial:\n",
        "          messages = [{\"role\": \"system\", \"content\": f\"SUGGEST TO BOOK AN APPOINTMENT ASAP. TODAY'S DATE IS  {str(datetime.now().strftime('%Y-%m-%d'))}\"}] + messages\n",
        "    elif len(dangerous_dict) > 0:\n",
        "      messages=[\n",
        "      {\"role\": \"system\", \"content\": \"You are a medical expert assistant called Dr. Hippo and you speak in greys anatomy acting style\"},\n",
        "      {\"role\":\"system\",\"content\":f''' the patient you are interacting has the following personal infomraitons: {medicat_str}.\n",
        "                                      He or she just received the following xray results that show a somewhat high probability of suffering of {str(dangerous_dict.keys())}. End the conversation by suggesting an appointment.\n",
        "                                      You can use the informations you know about the patient for further analysis.\n",
        "                                                                            Use LOADS of emoji in your message.''' },]\n",
        "      if initial:\n",
        "          messages = [{\"role\": \"system\", \"content\": f\"SUGGEST TO BOOK AN APPOINTMENT ASAP. TODAY'S DATE IS  {str(datetime.now().strftime('%Y-%m-%d'))}\"}] + messages\n",
        "\n",
        "\n",
        "    else:\n",
        "      messages=[\n",
        "      {\"role\": \"system\", \"content\": \"You are a medical expert assistant called Dr. Hippo and you speak in greys anatomy acting style\"},\n",
        "      {\"role\":\"system\",\"content\":f''' the patient you are interacting has the following personal infomraitons: {medicat_str}.\n",
        "                                      He or she just received the following xray results that show that the patient is healthy. Reassure them. If the user asks for health advice, take into account {medicat_str}.\n",
        "                                                                            Use LOADS of emoji in your message. SUGGEST TO BOOK AN APPOINTMENT IN ONE YEAR. TODAY'S DATE IS  {str(datetime.now().strftime(\"%Y-%m-%d\"))} ''' },]\n",
        "      # if initial:\n",
        "      #     messages = [{\"role\": \"system\", \"content\": f\"SUGGEST TO BOOK AN APPOINTMENT IN ONE YEAR. TODAY'S DATE IS  {str(datetime.now().strftime('%Y-%m-%d'))}\"}] + messages\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    for chat in chat_history:\n",
        "        messages.extend([{\"role\":\"user\",\"content\":chat[0]},\n",
        "                        {\"role\":\"assistant\",\"content\":chat[1]}])\n",
        "\n",
        "    messages.append({\"role\":\"user\",\"content\":\"given the medical knowledge you have about me\\n\"+ new_user_prompt})\n",
        "    print(messages)\n",
        "    completion = client.chat.completions.create(model=model, messages=messages, user=id_generator(), seed=1337)\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "\n",
        "def random_response(message, history):\n",
        "    global prediction_results\n",
        "    sorted_prediction_results= dict(sorted(prediction_results.items(), key=lambda item: item[1], reverse=True))\n",
        "\n",
        "    return f\"Biggest risk: {list(sorted_prediction_results.keys())[0]}\"\n",
        "\n",
        "def update_frame(button):\n",
        "  # global chat\n",
        "  # chat.clear()\n",
        "  latest_report = reports[button]\n",
        "  global prediction_results\n",
        "  prediction_results = latest_report['results']\n",
        "  first_msg = prompt_chatGPT(' what do I suffer from', [], initial=True)\n",
        "  return latest_report['img'], latest_report['results'], [['',first_msg]], [['',first_msg]], button\n",
        "\n",
        "theme = gr.themes.Base(\n",
        "    primary_hue=\"indigo\",\n",
        ")\n",
        "\n",
        "\n",
        "with gr.Blocks(js=js_func, theme=theme) as demo:\n",
        "  with gr.Tab('User Interface') as user_tab:\n",
        "      bot = gr.Chatbot(render=False, height=800)\n",
        "      with gr.Row():\n",
        "        with gr.Column(scale=0.5):\n",
        "          report_button = gr.Button('Reports', interactive=False)\n",
        "          with gr.Group():\n",
        "            buttons={}\n",
        "            for report_name in reports.keys():\n",
        "                buttons[report_name] = gr.Button(report_name)\n",
        "          df = gr.DataFrame(medical_df, headers=None)\n",
        "        with gr.Column(scale=1.4):\n",
        "          reportchat_button = gr.Button('HippoChat', interactive=False)\n",
        "\n",
        "          chat = gr.ChatInterface(prompt_chatGPT, chatbot=bot)\n",
        "        with gr.Column(scale=1.4):\n",
        "          reportreport_button = gr.Button('Report', interactive=True, variant='primary')\n",
        "\n",
        "          results_img =  gr.Image()\n",
        "          results_barplot = gr.Label(num_top_classes=7, show_label=False)\n",
        "\n",
        "      for button_name, report in reports.items():\n",
        "        buttons[button_name].click(update_frame, buttons[button_name], [results_img, results_barplot, bot, chat.chatbot_state, reportreport_button])\n",
        "\n",
        "  with gr.Tab('Technician Interface') as technician_tab:\n",
        "    with gr.Row():\n",
        "      with gr.Column():\n",
        "        input_img_interface = gr.Image()\n",
        "        run_button = gr.Button('Predict')\n",
        "      with gr.Column():\n",
        "        results_interface_tech = gr.Label()\n",
        "        with gr.Row():\n",
        "          send_to_user =  gr.Button('Send to Patient')\n",
        "          send_to_export=  gr.Button('Send to Expert', variant='stop')\n",
        "\n",
        "    run_button.click(predict, [input_img_interface], [results_interface_tech])\n",
        "demo.queue().launch(share=True, debug=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTGhIJFkRxlv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
